% !Mode:: "Tex:UTF-8"

<<setup, echo=FALSE, cache=FALSE, purl=FALSE>>=
## numbers >= 10^5 will be denoted in scientific notation,
## and rounded to 2 digits
options(scipen = 2, digits = 3, cache=FALSE)
opts_chunk$set(purl=FALSE) 
@

\documentclass[10pt,a4paper]{article}
\usepackage{etoolbox}
\newtoggle{color}
%\togglefalse{color}
\toggletrue{color}

\usepackage{makeidx}
\newcommand{\idioma}{spanish}
\newcommand{\opcionesIdioma}{,es-nodecimaldot,es-tabla}
\input{../tex/definiciones}
%\input{sahp}
\includecomment{com}
%\excludecomment{com}
%\usepackage[dvips]{hyperref}
%\usepackage{pstricks}


\newtoggle{distribuir}
%\togglefalse{distribuir}
\toggletrue{distribuir}
\iftoggle{distribuir}{%
  % color version
    \includecomment{distribuir}
    \excludecomment{noDistribuir}
}{%
  % b/w version
    \includecomment{noDistribuir}
    \excludecomment{distribuir}
}


\usepackage{attachfile}

\textwidth=150mm \textheight=260mm
\hoffset=-1cm
\voffset=-25mm
\parskip=2mm
%\textwidth=160mm \textheight=240mm \hoffset=-20mm \voffset=-20mm \parskip=0mm \marginparsep=-25mm

\setlength{\parindent}{0pt}
\newcounter {cont01}

\externaldocument[curso-]{../CursoIntroduccionEstadistica/000-CursoEstadistica}
\externaldocument[tut01-]{../TutorialesR/Tutorial-01}
\externaldocument[tut02-]{Tutorial-02-py}
\externaldocument[tut03-]{Tutorial-03-py}

<<echo=FALSE, eval=FALSE, purl=FALSE>>=
setwd("~/Dropbox/PostDataFernando/TutorialesPython")
source("~/Dropbox/Code/R/raptor/raptor.R")
library(knitr)
purl("Tutorial-04-py.Rnw", output="./code/Tut04-VariableAleatoriaDiscreta.py", documentation = 0)
# filename = "Tutorial-04-py.Rnw"
# language = "python"
# fileOverwrite = TRUE
# keepAux = TRUE
# defaultExecOrder = Inf
raptor(filename = "Tutorial-04-py.Rnw", language = "python", fileOverwrite = TRUE, keepAux = TRUE, defaultExecOrder = Inf)
@


<<echo=FALSE, purl=FALSE>>=
library(knitr)
# Este tutorial contiene el código de varios ficheros, que se extrae 
# descomentando y ejecutando los siguientes bloques.
Tut04_VariableAleatoriaDiscreta = FALSE
#####################################
# Tut04_VariableAleatoriaDiscreta = TRUE
# purl("Tutorial-04-py.Rnw", output="./code/Tut04-VariableAleatoriaDiscreta.py", documentation = 0)
# Tut04_VariableAleatoriaDiscreta = FALSE
#####################################
@


<<eval=FALSE, echo=FALSE, putl=Tut04_VariableAleatoriaDiscreta, comment=NULL>>=
# -*- coding: utf-8 -*-
## ---- Tut04-VariableAleatoriaDiscreta
"""
www.postdata-statistics.com
POSTDATA. Introducción a la Estadística
Tutorial 04.  
Fichero de comandos Python para el estudio de 
una variable aleatoria discreta.
"""
## Importacion de Modulos

import numpy as np 
import matplotlib.pyplot as plt
import math as m 

@



\begin{document}
\includecomment{pdf}
%\excludecomment{pdf}
%\includecomment{dvi}
\excludecomment{dvi}
%\includecomment{com}
\excludecomment{com}


\paragraph{\link{http://www.postdata-statistics.com/}{PostData}\hspace{6.3cm}Curso de Introducción a la Estadística\\[2mm]} \noindent\hrule

\setcounter{section}{0}
\section*{\hspace{-0.1cm}\fbox{\colorbox{Gris025}{
\begin{minipage}{14.5cm}
Tutorial 04 (versión Python): Variables aleatorias.
\end{minipage}
}}}
{
Atención:
\begin{itemize}
  \item Este documento pdf lleva adjuntos algunos de los ficheros de datos necesarios. Y está pensado para trabajar con él directamente en tu ordenador. Al usarlo en la pantalla, si es necesario, puedes aumentar alguna de las figuras para ver los detalles. Antes de imprimirlo, piensa si es necesario. Los árboles y nosotros te lo agradeceremos.
  \item Fecha: \today. Si este fichero tiene más de un año, puede resultar obsoleto. Busca si existe una versión más reciente.
\end{itemize}
}
\setcounter{tocdepth}{1}
\tableofcontents

\section{Variables aleatorias discretas con Python.}
\label{tut04:sec:VariablesAleatoriasDiscretas}

\subsection{Tabla (función) de densidad de una variable aleatoria discreta.}
\label{tut04:subsec:TablaDensidadVariableAleatoriaDiscreta}

Una variable aleatoria discreta $X$ que toma los valores
\[x_1, x_2, \ldots, x_k\]
se define mediante su tabla de densidad de probabilidad:
    \begin{center}
    \begin{tabular}[t]{|c|c|c|c|c|c|}
    \hline
    \rule{0cm}{0.5cm}{\em Valor:}&$x_1$&$x_2$&$x_3$&$\cdots$&$x_k$\\
    \hline
    \rule{0cm}{0.7cm}{\em Probabilidad:}&$p_1$&$p_2$&$p_3$&$\cdots$&$p_k$\\
    \hline
    \end{tabular}
    \end{center}
Como ya hemos dicho, las probabilidades se pueden entender, en muchos casos, como una versión teórica de las frecuencias relativas. Así que esta tabla se parece mucho a una tabla de frecuencias relativas, y parte de las operaciones que vamos a hacer nos recordarán mucho a las que hicimos en la primera parte del curso usando tablas de frecuencias.

La primera variable aleatoria que vamos a estudiar va a ser, como en el Ejemplo \ref{curso-cap04:ejem:VariableAleatoriaSumaDosDados} del libro (pág. \pageref{curso-cap04:ejem:VariableAleatoriaSumaDosDados}), la variable $X$ cuyo valor es el resultado de sumar los puntos obtenidos al lanzar dos dados. Para estudiarla, vamos a recordar algunas de las técnicas de simulación que aprendimos en el Tutorial03. Usaremos listas de Python para reproducir los resultados de ese Ejemplo \ref{curso-cap04:ejem:VariableAleatoriaSumaDosDados}. Concretamente, los resultados posibles al tirar el primer dado son:
<<raptor="python", purl=FALSE, program="dosDados">>=
dado1 = range(1,7)
print(list(dado1))
@

\newpage
Ahora hacemos lo mismo para el segundo dado:
<<raptor="python", purl=FALSE, program="dosDados">>=
dado2 = range(1,7)
@
Las sumas posibles se obtienen entonces así usando una comprensión de listas:
<<raptor="python", purl=FALSE, program="dosDados">>=
suma = [d1 + d2 for d1 in dado1 for d2 in dado2]
print(suma)
@
Para hacer el recuento de las veces que aparece cada uno de los valores posibles de la suma podemos usar los métodos que aprendimos en el Tutorial02 y hacer una tabla de frecuencias:
<<raptor="python", purl=FALSE, program="dosDados">>=
import collections as cl
sumaCounter = cl.Counter(suma)
recuentoValoresSuma = sumaCounter.most_common()
recuentoValoresSuma.sort()
print(recuentoValoresSuma)
@
Para convertir estos recuentos en probabilidades tenemos que dividirlos por el número de resultados posibles, que son $36$. Recuerda que el resultado de la división en Python nos va a proporcionar respuestas numéricas (no {\em simbólicas}) y por lo tanto, aproximadas:
<<raptor="python", purl=FALSE, program="dosDados">>=
n = len(suma)
print("n=", n)
probabilidadesSuma = [[item[0], item[1]/n] for item in recuentoValoresSuma]
print("probabilidadesSuma=", probabilidadesSuma)
@
Estos resultados son (las versiones numéricas de) los mismos que aparecen en la Tabla \ref{curso-cap04:tabla:probabilidadSumaDados} del libro (pág. \pageref{curso-cap04:tabla:probabilidadSumaDados}). Por ejemplo, la probabilidad correspondiente al valor $5$ es $\dfrac{4}{36}$ que es, aproximadamente:
<<raptor="python", purl=FALSE>>=
print(4/36)
@
Y es muy importante no perder de vista que, en tanto que probabilidades, se trata de valores teóricos. Lo que vamos a hacer a continuación es una simulación del experimento que consiste en lanzar dos dados y sumarlos, para comparar las frecuencias (empíricas o experimentales) que obtenemos con esas probabilidades (teóricas) que predice la variable $X$.

\begin{ejercicio}
\label{tut04:ejercicio01}
\quad\\
Este ejercicio debería resultar sencillo, después del trabajo de los tutoriales previos. Lo que queremos es simular $n=1000000$ tiradas de dos dados, y calcular la tabla de frecuencias relativas de la variable \[X=\{\mbox{suma de los dos dados}\}.\]
Solución en la página \pageref{tut04:ejercicio01:sol}.
\qed
\end{ejercicio}

%\subsection{Función (tabla) de densidad de una variable aleatoria discreta. }
%\label{tut04:subsec:TablaDensidad}
%
%Puesto que estamos trabajando con

\subsection{Media, varianza y desviación típica.}
\label{tut04:subsec:MediaVarianzaDesviacionTipica}

En este apartado vamos a ocuparnos de los cálculos necesarios para trabajar con una
variable aleatoria discreta $X$, dada mediante una tabla de valores y probabilidades (la tabla de densidad de probabilidad) como esta:
\[
\begin{array}{c|c|c|c|c|}
    \mbox{Valor}&x_1&x_2&\cdots&x_k \\
    \hline
    \mbox{Probabilidad}&p_1&p_2&\cdots&p_k
\end{array}
\]
La teoría correspondiente se encuentra en  el Capitulo \ref{curso-cap:VariablesAleatorias} del libro. A partir de la información de esta tabla, queremos calcular la media $\mu_X$ de $X$ y la varianza $\sigma^2_X$ de $X$. Vamos a aprender a utilizar Python para calcularlos.

Para fijar ideas vamos a pensar en un ejemplo concreto. Supongamos que la densidad de probabilidad de la variable $X$ es esta:
\[
\begin{array}{c|c|c|c|c|c|}
    \mbox{Valor}&2&4&7&8&11\\
    \hline
    \mbox{Probabilidad}&1/5&1/10&1/10&2/5&1/5
\end{array}
\]
Vamos a almacenar los valores y las probabilidades, en una lista de pares. El primer elemento de cada par es el valor y el segundo la probabilidad de ese valor:
<<echo=FALSE, eval=FALSE, comment=NULL, putl=Tut04_VariableAleatoriaDiscreta>>=

# Definicion de X a partir de valores y probabilidades.

valoresX = [2, 4, 7, 8, 11]
probabilidadesX = [1/5, 1/10, 1/10, 2/5, 1/5]
X = [[valoresX[_], probabilidadesX[_]] for _ in range(0, len(valoresX))]

# Alternativamente, definicion de la variable X como lista de pares [valor, probabilidad].
# Descomentar la siguiente linea para usarla.

# X = [[2, 1/5], [4, 1/10], [7, 1/10], [8, 2/5], [11, 1/5]]

# En cualquier caso:

valoresX = [x[0] for x in X]
probabilidadesX = [x[1] for x in X]

@
<<raptor="python", purl=FALSE>>=
# Definicion de la variable X.
X = [[2, 1/5], [4, 1/10], [7, 1/10], [8, 2/5], [11, 1/5]]
@
Y ahora, para calcular la media, haremos:
<<raptor= "python", putl=Tut04_VariableAleatoriaDiscreta, echo=-1>>=
# Calculo de la media.

media = sum([x[0] * x[1] for x in X])
print("Media de X = {0:0.4f}".format(media))

@
mientras que la varianza y desviación típica se obtienen importando el módulo {\tt math}:
<<raptor= "python", purl=FALSE>>=
import math as m
@
haciendo
<<raptor= "python", putl=Tut04_VariableAleatoriaDiscreta, echo=-1>>=
# Calculo de la varianza y desviacion tipica.

varianza = sum([(x[0] - media)**2 * x[1] for x in X])
print("varianza = {0:0.4f}".format(varianza))
@
y después:
<<raptor= "python", putl=Tut04_VariableAleatoriaDiscreta>>=

sigma = m.sqrt(varianza)
print("desviacion tipica = {0:0.4f}".format(sigma))

@


\begin{ejercicio}
\label{tut04:ejercicio02}
\quad\\
\begin{enumerate}
  \item Comprueba, usando Python, los resultados de los Ejemplos \ref{curso-ejem:Cap04:VariableAleatoriaSumaDosDadosMedia} y \ref{curso-cap04:ejem:varianzaVariableAleatoriaDiscreta} del libro (págs. \pageref{curso-ejem:Cap04:VariableAleatoriaSumaDosDadosMedia} y \pageref{curso-cap04:ejem:varianzaVariableAleatoriaDiscreta}, respectivamente), en lo que se refiere a la variable $X$, suma de dos dados.

  \item En el apartado anterior habrás obtenido un valor numérico (aproximado) de la varianza de $X$. Usa un programa simbólico (Wiris o Wolfram Alpha, por ejemplo) para calcular el valor exacto de la varianza.

  \item  Repite los apartados anteriores para la variable $Y$, la diferencia (en valor absoluto) de los dos dados.


\end{enumerate}

Solución en la página \pageref{tut04:ejercicio02:sol}.
\qed
\end{ejercicio}

\subsection{Operaciones con variables aleatorias.}
\label{tut04:subsec:OperacionesVariablesAleatorias}

En el Ejercicio \ref{tut04:ejercicio02} acabamos de calcular la media y varianza de las variables $X$ e $Y$, que representan la suma y diferencia de los resultados al lanzar dos dados, respectivamente. Vamos a usar estas dos variables para experimentar con los resultados teóricos que aparecen en la Sección \ref{curso-sec:OperacionesVariablesAleatorias} del libro (pág. \pageref{curso-sec:OperacionesVariablesAleatorias}).

Es importante recordar siempre que las variables aleatorias son modelos {\em teóricos} de las asignaciones de probabilidad. La media $\mu_X$ de la variable aleatoria $X$ representa el valor medio esperado en una serie muy larga de repeticiones del suceso aleatorio que representa la variable $X$.  Por tanto, la media sirve para hacer predicciones {\em teóricas} y, en cada casos concreto, los valores que obtendremos serán {\em parecidos, pero no idénticos} al valor que predice la media.

Para ilustrar esto, vamos a tomar como punto de partida la variable $X$ (suma al lanzar dos dados), y definiremos una nueva variable:
\[ W = 3\cdot X - 4.\]
La teoría predice que ha de ser:
\[ E(W) = E(3\cdot X - 4)= 3\cdot E(X) -4\]
y, usando los resultados del Ejercicio \ref{tut04:ejercicio02} de este tutorial, tenemos
\[ E(W) = 3\cdot E(X) - 4 = 3\cdot 7 - 4 =17.\]
Para {\em ``comprobar experimentalmente''} esta predicción teórica vamos a fabricar una serie muy larga ($n = 10000$) de valores aleatorios de $W$, y calcularemos su media. Los valores de $W$ se obtienen de los de $X$ con este código Python (la primera parte es muy parecida al comienzo de la solución del Ejercicio \ref{tut04:ejercicio01}):
<<raptor="python", purl=FALSE>>=
import random as rnd
rnd.seed(2016)
n = 10000
dado1 = [rnd.randrange(1, 7) for _ in range(0, n)]
dado2 = [rnd.randrange(1, 7) for _ in range(0, n)]
X = [dado1[_] + dado2[_] for _ in range(0, n)]
W = [3 * x - 4 for x in X]
@
La novedad, naturalmente, es esa última línea, en la que calculamos los valores de $W$ a partir de los de $X$. La media de esos $10000$ valores de $W$ es:
<<raptor="python", purl=FALSE>>=
import numpy as np
mediaW = np.mean(W)
print("media de W= {0:0.4f}".format(mediaW))
@
Hemos usado la función {\tt mean} de {\tt numpy} para obtener el resultado. Y, como puedes ver, el resultado del experimento se parece mucho a nuestra predicción teórica.

Vamos a aprovechar, también, para comprobar que las cosas no siempre son tan sencillas. En particular, vamos a usar la variable
\[V = X^2\]
para comprobar que:
\[E(V) = E(X^2) \neq (E(X))^2 = 7^2 = 49.\]
Aquí, de nuevo, $X$ es la variable suma al lanzar dos dados. Para comprobar {\em experimentalmente} esto procedemos de forma muy parecida a lo que acabamos de hacer con $W$. Generamos una lista de valores de $V$, y calculamos su media:
<<raptor= "python", purl=FALSE>>=
V = [x**2 for x in X]
mediaV = np.mean(V)
print("media de V= {0:0.4f}".format(mediaV))
@
¿Cuál es el cálculo teórico correspondiente? Para calcular la media de $V = X^2$ empezamos por hacer la tabla de densidad de esta variable. Esa tabla se obtiene fácilmente de la Tabla \ref{curso-ejem:Cap04:VariableAleatoriaSumaDosDadosMedia} del libro (pág. \pageref{curso-ejem:Cap04:VariableAleatoriaSumaDosDadosMedia}), elevando los valores al cuadrado (las probabilidades se mantienen):

\begin{center}
    {\small
    \begin{tabular}[t]{|c|c|c|c|c|c|c|c|c|c|c|c|}
    \hline
    Valor\rule{0cm}{0.5cm}
    &4&9&16&25&36&49&64&81&100&121&144\\
    \hline
    Probabilidad\rule{0cm}{0.7cm}
    &$\dfrac{1}{36}$&$\dfrac{2}{36}$&$\dfrac{3}{36}$&$\dfrac{4}{36}$&$\dfrac{5}{36}$&$\dfrac{6}{36}$&$\dfrac{5}{36}$&$\dfrac{4}{36}$&$\dfrac{3}{36}$&$\dfrac{2}{36}$&$\dfrac{1}{36}$\\
    &&&&&&&&&&&\\
    \hline
    \end{tabular}
    }
\end{center}
Y ahora puedes usar cualquier programa (Wolfram Alpha, o el propio R) para comprobar que:
\[\mu_V = \dfrac{1974}{36} \approx 54.83.\]
Fíjate en que este valor se parece mucho más al que hemos obtenido en la versión experimental del cálculo.

Los resultados que acabamos de obtener confirman que la media no se lleva bien con el cuadrado: la media del cuadrado no es el {\em ``cuadrado de la media''}. De hecho, la diferencia entre esas dos cantidades es, precisamente, la varianza:
\[\operatorname{Var}(X) = E(X^2) - \left(E(X)\right)^2.\]
Sin entrar a dar una demostración teórica de este hecho, vamos a comprobarlo usando la variable $X$. Empezamos repitiendo los mismos cálculos que aparecen en la solución del Ejercicio \ref{tut04:ejercicio02} (ver página \pageref{tut04:ejercicio02:sol}).
<<raptor="python", purl=FALSE>>=
valoresX = range(2, 13)
probabilidadesX = list(range(1,7)) + list(range(5, 0, -1))
probabilidadesX = [p/36 for p in probabilidadesX]
muX = sum([valoresX[i] * probabilidadesX[i] for i in range(0, len(valoresX))])
print("Media de X = {0:0.4f}".format(muX))
varX = sum( [(valoresX[i] - muX)**2 * probabilidadesX[i] for i in range(0, len(valoresX))])
print("Varianza de X = {0:0.4f}".format(varX))
@
Recuerda que el cálculo que estamos haciendo aquí es teórico (no es un ``experimento''). Ahora vamos a calcular la media de $V=X^2$:
<<raptor="python", purl=FALSE>>=
valoresV = [x**2 for x in valoresX]
probabilidadesV = probabilidadesX
muV = sum([valoresV[i] * probabilidadesV[i] for i in range(0, len(valoresV))])
print("Media de V = {0:0.4f}".format(muV))
@
Y ahora podemos comprobar, en este ejemplo, la identidad $\operatorname{Var}(X) = E(X^2) - \left(E(X)\right)^2$. Se tiene:
<<raptor="python", purl=FALSE>>=
print("varX ={0:0.4f}".format(varX))
print("muV - (muX)^2 ={0:0.4f}".format(muV - (muX)**2))
@
como esperábamos. Naturalmente, este resultado teórico también se puede comprobar experimentalmente. Y es interesante hacerlo, así que lo exploraremos en los ejercicios adicionales.


\subsection{Función de distribución (probabilidad acumulada)}
\label{tut04:subsec:FuncionDistribucion}


La función de distribución de la variable aleatoria $X$ es, recordémoslo:
\[F(k)=P(X\leq k)\]
Es decir, que dado el valor de $k$, debemos sumar todos los valores de la densidad de probabilidad para valores menores o iguales que $k$. En el ejemplo de la variable $X$ que aparece al comienzo de la Sección \ref{tut04:subsec:MediaVarianzaDesviacionTipica} (pág. \pageref{tut04:subsec:MediaVarianzaDesviacionTipica}), si queremos calcular $F(7)$, debemos hacer:
\[F(7)=P(X=2)+P(X=4)+P(X=7)=\frac{1}{5}+\frac{1}{10}+\frac{1}{10}.\]
Se trata de sumas acumuladas, como las que vimos en el caso de las tabla de frecuencias acumuladas. Así que usaremos lo que aprendimos en el Tutorial02 (Sección \ref{tut02-tut02:subsec:PorFinHagamosEstadisticaDescriptiva}). Vamos a empezar por extraer las probabilidades de  la variable $X$:
<<raptor="python", purl=FALSE>>=
X = [[2, 1/5], [4, 1/10], [7, 1/10], [8, 2/5], [11, 1/5]]
valoresX = [item[0] for item in X]
probabilidadesX = [item[1] for item in X]
print(probabilidadesX)
@
Y ahora aplicamos la función {\tt cumsum} de {\tt numpy} así:
<<eval=FALSE, echo=FALSE, comment=NULL, putl=Tut04_VariableAleatoriaDiscreta>>=
# Función de distribucion.

FdistX = np.cumsum(probabilidadesX).tolist()

@
<<raptor= "python", purl=FALSE, echo=-1>>=
FdistX = np.cumsum(probabilidadesX).tolist()
print(FdistX)
@
que, como ves, produce un vector con los valores de $F(k)$ para cada $k$. Seguramente preferiremos ver estos resultados en forma de tabla, para poder localizar fácilmente el valor de $F$ que corresponde a cada valor de $k$. Con lo que hemos aprendido sobre la función {\tt print}, es fácil conseguirlo. Pondríamos:
<<eval=FALSE, echo=FALSE, comment=NULL, putl=Tut04_VariableAleatoriaDiscreta>>=
# y su tabla:

k = len(valoresX)
print("\nTabla de densidad de la variable aleatoria X:\n")
linea = "_" * 49
print(linea)
print("| Valor x | Probabilidad p | Fun. de dist. F(x) |")
print(linea)
for i in range(0, k):
    print("| {0: 7d} | {1: 14.2f} | {2: 18.2f} |".format(valoresX[i],\
          probabilidadesX[i], FdistX[i]))
print(linea)

@
<<eval=FALSE, comment=NULL, background='#99ccff', purl=FALSE>>=
k = len(valoresX)
print("\nTabla de la variable aleatoria X:\n")
linea = "_" * 49
print(linea)
print("| Valor x | Probabilidad p | Fun. de dist. F(x) |")
print(linea)
for i in range(0, k):
    print("| {0: 7d} | {1: 14.2f} | {2: 18.2f} |".format(valoresX[i],\
          probabilidadesX[i], FdistX[i]))
print(linea)
@
\vspace{-4mm}
<<eval=FALSE, comment=NULL, background='#cce6ff', purl=FALSE>>=
Tabla de la variable aleatoria X:

_________________________________________________
| Valor x | Probabilidad p | Fun. de dist. F(x) |
_________________________________________________
|       2 |           0.20 |               0.20 |
|       4 |           0.10 |               0.30 |
|       7 |           0.10 |               0.40 |
|       8 |           0.40 |               0.80 |
|      11 |           0.20 |               1.00 |
_________________________________________________
@
Aunque en esta tabla sólo aparecen los valores $2, 4, 7, 8$ y $11$, es bueno recordar que la función de distribución $F(x)$ está definida {\em sea cual sea el valor de $x$}. Es decir, que tiene prefecto sentido preguntar, por ejemplo, cuánto vale $F(\frac{8}{3})$. Más adelante vermeos la forma de conseguir que Python conteste esta pregunta automáticamente, pero todavía tenemos que aprender algunas cosas más sobre el lenguaje antes de ver cómo podemos conseguir eso.

\begin{ejercicio}
\label{tut04:ejercicio03}
\quad\\
¿Cuánto vale $F(\frac{8}{3})$? Aunque no forme parte del ejercicio, trata de ir pensando en un procedimiento que te permita, dado un valor $x$ cualquiera, obtener el valor $F(x)$.
Solución en la página \pageref{tut04:ejercicio03:sol}.
\qed
\end{ejercicio}

\subsection{Representación gráfica de las variables aleatorias.}
\label{tut04:subsec:RepresentacionGraficaDistribuciones}

Dada una variable aleatoria $X$, por ejemplo la que venimos usando desde el comienzo de la Sección \ref{tut04:subsec:MediaVarianzaDesviacionTipica}, podemos representar gráficamente su tabla de densidad de probabilidad, en un diagrama de columnas, usando la función {\tt bar} de {\tt matplotlib} (que ya encontramos en el Tutorial02). Empezamos importando el módulo:
<<raptor = "python", purl=FALSE>>=
import matplotlib.pyplot as plt
@
Y luego usaremos estos comandos:
<<raptor = "python", purl=Tut04_VariableAleatoriaDiscreta, echo =-(1:2), results='hide'>>=
# Gráfico de barras de la función de densidad.

plt.suptitle("Gráfico de barras de la función de densidad:")
plt.xticks(valoresX)
plt.axis([min(valoresX) - 1,max(valoresX) + 1, 0, 1])
plt.bar(valoresX, probabilidadesX, color='tan', align='center')

@
<<raptor="python", echo=FALSE, eval=FALSE, purl=FALSE>>=
plt.savefig('../fig/Tut-04-py-01.png')
@
El resultado es esta figura:
\begin{center}
\includegraphics[height=12cm]{../fig/Tut-04-py-01.png}
\end{center}
Algunos comentarios: 
\begin{itemize}
  \item La función {\tt suptitle} añade un título al gráfico.
  \item La función {\tt xticks} nos sirve para indicarle a Python donde queremos que vayan situadas las etiquetas del eje $x$. En relación con esto, en la función {\tt bar} hemos usado la opción {\tt align='center'} para situar las etiquetas en el centro de cada columna (y no al principio). Esta era una tarea que habíamos dejado pendiente en el Tutorial02.
  \item La función {\tt axis} sirva para fijar la {\tt em ventana gráfica} que Python usará en la figura. Lo hacemos mediante una lista de cuatro valores que definen los valores mínimo y máximo, primero del eje $x$ y luego del eje $y$. Para este ejemplo concreto nos hemos asegurado de que el eje $x$ cubra todo el rango de valores de la variable $X$, con un margen de una unidad extra por cada lado, y que el eje $y$ recorra los valores del $0$ al $1$, puesto que se trata de probabilidades.
\end{itemize}
<<raptor = "python", putl=Tut04_VariableAleatoriaDiscreta, echo=FALSE, eval=FALSE, comment=NULL>>=
#   Reset gráfico.

plt.figure()

@


\paragraph{}\label{tut04:fig:graficoFuncionDistribucion} Para representar la función de distribución es más común utilizar {\em gráficos de escalera} como el que aparece en la Figura \ref{curso-cap04:fig:GraficaFuncionDistribucionVariableAleatoriaDiscreta} del libro (página \pageref{curso-cap04:fig:GraficaFuncionDistribucionVariableAleatoriaDiscreta}). En Python hay varias maneras de hacerlo, más o menos complicadas. Aquí vamos a ver una bastante sencilla, que usa la función {\tt step} (en el sentido inglés de {\em peldaño}). Como verás, en esa función hemos hecho algunos retoques, añadiendo en el eje $x$ un valor a la izquierda del recorrido de $X$ y uno a su derecha, que se corresponden con los valores $0$ y $1.00001$ del eje $y$. Lo hemos hecho para obligar a Python a crear una perspectiva algo más amplia de la función de distribución. 



<<raptor = "python", putl=Tut04_VariableAleatoriaDiscreta, echo =-(1:2)>>=
# Gráfico de escalera de la función de distribucion.

plt.suptitle("Gráfico de escalera de la función de distribucion:")
plt.xticks(valoresX)
plt.step([min(valoresX) - 2] + valoresX + [max(valoresX) + 1],
         [0] + FdistX + [1.00001], where='post', linewidth=4.0, color='red')
@

<<raptor="python", echo=FALSE, eval=FALSE, purl=FALSE>>=
plt.savefig('../fig/Tut-04-py-02.png')
@

El resultado es esta figura:
\begin{center}
\includegraphics[height=12cm]{../fig/Tut-04-py-02.png}
\end{center}
que, si bien dista de ser perfecta, es suficiente mientras recuerdes que las funciones de distribución son {\em continuas por la derecha}; en términos más sencillos, que los puntos gordos de la Figura \ref{curso-cap04:fig:GraficaFuncionDistribucionVariableAleatoriaDiscreta} del libro (pág. \pageref{curso-cap04:fig:GraficaFuncionDistribucionVariableAleatoriaDiscreta}) están en el extremo izquierdo de los peldaños.

\subsection{Un fichero de comandos Python para estudiar una variable discreta.}
\label{tut04:subsec:FicheroComandosRParaVaraiableDiscreta}

Al igual que hicimos en el Tutorial02, en el que incluimos un fichero que resumía muchos comandos de Estadística Descriptiva, vamos a incluir aquí un {\em fichero plantilla} que reúne los comandos que hemos ido viendo en este Tutorial para trabajar con una variable aleatoria discreta (con un número finito de valores) definida mediante su tabla de densidad:
\begin{center}
\fichero{./code/Tut04-VariableAleatoriaDiscreta.py}{Tut04-VariableAleatoriaDiscreta.py}
\end{center}
cuyo listado es:
<<echo=FALSE, purl=FALSE>>=
read_chunk("./code/Tut04-VariableAleatoriaDiscreta.py")
@
<<eval=FALSE, comment=NULL, purl=FALSE>>=
<<Tut04-VariableAleatoriaDiscreta>>
@


\section{Funciones definidas por el usuario en Python.}
\label{tut04:sec:funcionesUsuarioPython}
\noindent{\bf Opcional: aunque esta sección puede omitirse en una primera lectura, pronto se hará necesaria.}\\

En esta sección vamos a aprender a escribir nuestras propias funciones Python. Antes de discutir más a fondo sobre el uso de las funciones empezaremos por ver  algunos ejemplos muy sencillos. De esa forma confíamos en que te resulte más fácil entender la discusión sobre la necesidad y conveniencia de las funciones.

Vamos por tanto con el primero de esos ejemplos, que va a ser sencillo porque de momento queremos centrarnos en la forma de escribir una función. En concreto, vamos a escribir una función de Python, a la que llamaremos {esCuadrado} y que, dado un número entero $n$, nos diga si ese número es un cuadrado perfecto. La respuesta será un valor booleano, {\tt True} or {\tt False}, según que el número sea o no un cuadrado perfecto. Por ejemplo, queremos que al ejecutar:
<<eval=FALSE, purl=FALSE>>=
esCuadrado(9)
@
la respuesta sea {\tt True}, porque $9 = 3^2$, mientras que al ejecutar  
<<eval=FALSE, purl=FALSE>>=
esCuadrado(7)
@
queremos que la respuesta sea {\tt False}. 

Una función es, un cierto sentido, como un programa dentro de nuestro programa. Así que para diseñar la función empezamos usando pseudocódigo, como hacíamos con los programas. En este caso, por ejemplo, el plan es este:
<<eval=FALSE, comment=NULL, purl=FALSE>>=
1. Calcular la raíz cuadrada de n (que será un número real, no necesariamente entero).
2. Redondearla al entero más cercano.
3. Elevar ese entero al cuadrado y comprobar si coincide con $n$.
4. Si coincide responder True, en caso contrario responder False.
@
Usando ese pseudocódigo como referencia, crear la función es muy sencillo. Primero nos aseguramos de haber importado el módulo {\tt math}:
<<raptor="python", purl=FALSE>>=
import math as m
@
y ahora vamos con la función propiamente dicha:
<<raptor="python", purl=FALSE>>=
def esCuadrado(n):
  """
  Devuelve True si el entero n es un cuadrado perfecto y False en caso contrario.  
  """
  raiz = m.sqrt(n)
  raizRedondeada = round(raiz)
  if(raizRedondeada**2 == n):
    return(True)
  else:
    return(False)
@
Enseguida vamos a analizar detenidamente este código. Pero antes, veamos cómo funciona en el par de casos que antes hemos propuesto:
<<raptor="python", purl=FALSE>>=
print(esCuadrado(9))
@
Y de modo análogo:
<<raptor="python", purl=FALSE>>=
print(esCuadrado(7))
@
Como ves, la función que hemos creado se usa como cualquier otra función de Python. Vamos con el análisis del código de la función.

\begin{enumerate}
  \item La primera línea, la {\sf cabecera} de la función, comienza con la palabra clave {\tt def}. Esa palabra sirve para avisar a Python de que comienza la definición de una función. A continuación escribimos el nombre de la función {\tt esCuadrado} y, entre paréntesis, el argumento (o argumentos, como veremos pronto) de la función, que en este caso es el número {\tt n}. La línea de cabecera termina con dos puntos que, como ya vamos reconociendo, es la forma de indicar en Python que comienza un {\em bloque} de instrucciones.
  
  \item Las siguientes líneas indentadas forman lo que denominamos el {\sf cuerpo} de la función. Python detecta el final de la función cuando desaparece esa indentación y volvemos al nivel de la línea de cabecera. Si escribes funciones en un buen editor de texto, que reconozca la sintaxis de Python, te resultará más fácil adaptarte a esta escritura de las funciones, porque el editor se encargará de forma automática de dar formato a lo que escribas.
  
  \item Las primeras líneas del cuerpo de la función, delimitadas por las dos líneas que continenen tres comillas dobles \verb&"""& forman un {\sf bloque de documentación inicial} de la función. Nos hemos encontrado ya con este tipo de bloques de comentarios que ocupan varias líneas en las cabeceras de nuestros ficheros plantilla. Y al igual que sucede con el otro tipo de comentarios que ya conocemos (y que usan \verb&#&), cuando Python encuentra estas líneas al principio del código de una función simplemente las ignora. De esa forma disponemos de un espacio en el que explicar qué es lo que hace la función. Como ocurre casi siempre con la documentación del código, no es en absoluto necesario que exista este bloque para que la función haga su trabajo correctamente. Pero hemos querido desde el primer ejemplo incluir la documentación como parte esencial de la escritura de la función, porque como repetiremos varias veces a lo largo del curso, {\bf el código mal documentado es una mala práctica}. Más adelante volveremos sobre estas líneas iniciales de la función y sobre las diferencias entre usar \verb&"""& y usar \verb&#&.
  
  \item Como puedes ver, las restantes líneas del cuerpo de la función son simplemente instrucciones Python que ya conocemos y que traducen los pasos que hemos enumerado antes en el pseudocódigo. El cuerpo de la función incluye, al final, un bloque {\tt if/else}. Hemos elegido este ejemplo para ilustrar el hecho  de que el cuerpo de una función puede contener muchos de los elementos que hemos ido conociendo del lenguaje Python: asignaciones, bucles {\tt for}, sentencias {\tt if/else}, como en este ejemplo. Además  la sentencia sentencias {\tt if/else} de nuestro ejemplo contiene otro ingrediente fundamental de una función en Python: la función {\tt return}.
  
  \item Toda función Python debería incluir al menos una llamada a la función {\tt return}. El argumento de esa función define el valor que la función devuelve cuando la invocamos. En este ejemplo, como ves, tenemos dos apariciones de {\tt return}. En la primera el valor que devuelve la función {\tt esCuadrado} es {\tt True}, y en la segunda es {\tt False}. Fijate en que podríamos haber escrito la función de manera que sólo hubiera una aparición de {\tt return}. Por ejemplo, así: 
<<raptor="python", purl=FALSE>>=
def esCuadrado(n):
  """
  Devuelve True si el entero n es un cuadrado perfecto y False en caso contrario.  
  """
  raiz = m.sqrt(n)
  raizRedondeada = round(raiz)
  if(raizRedondeada**2 == n):
    respuesta = True
  else:
    respuesta = False
  return(respuesta)
@  
Pero a veces es más natural usar varias veces {\tt return}. En algunas ocasiones nos encontraremos con funciones en las que no es necesario definir un resultado de salida. Por ejemplo, funciones que producen un objeto externo como un fichero de datos o una figura. En esos casos se puede usar la función return sin argumentos, así:
<<eval=FALSE, purl=FALSE, comment=NULL>>=
return()
@
De esa forma simplemente le indicamos a Python que la ejecución de la función ha terminado. Cuando aprendas más sobre Python descubirás que, en cualquier caso, siempre suele ser buena idea que la función produzca algún valor de salida. Por ejemplo, si la función crea un fichero de datos, el valor de salida puede ser un código que nos permita saber si el proceso de creación del fichero ha tenido éxito o si, por el contrario, se ha producido un problema y de qué tipo.

\end{enumerate}

En cualquier caso, es importante saber que, tras ejecutar {\tt return}, Python considera terminada la ejecución de la función y devuelve el control al punto de nuestro programa desde el que se invocó a la función.  También es necesario saber que el valor que devuelve la función puede ser cualquiera de los objetos Python que hemos ido encontrando: números, booleanos o cadenas de caracteres, desde luego. Pero también listas, tuplas, etc. Incluso podemos tener funciones que produzcan como resultado otra función. En estos tutoriales tendremos ocasión de encontrarnos con algunas funciones más complejas.  

\subsubsection*{¿Para qué sirve escribir nuestras propias funciones?}

Desde el comienzo de nuestro trabajo con Python hemos ido aumentando la colección de funciones del lenguaje que conocemos. Las funciones son un ingrediente esencial de cualquier lenguaje de programación moderno.  Y Python cuenta con una colección extensísima de funciones, especialmente gracias a la enorme cantidad de módulos que podemos importar. ¿Por qué son tan importantes las funciones en Programación? En su libro {\em Think Python} (ver la referencia \cite{downey2015thinkPython} al final del tutorial), Allen B. Downey cita varias razones, que en esencia son estas: 
\begin{itemize}
   \item Escribir una función hace que nuestro código sea más fácil de escribir y leer. Sólo por eso ya merecerían la pena.
   
   \item Relacionado con lo anterior, las funciones simplifican enormemente el mantenimiento del código. Una máxima que conviene recordar es que el tiempo más valioso no es normalmente el tiempo que el ordenador pasa ejecutando el programa, sino el tiempo que el programador pasa escribiéndolo y corrigiéndolo. 
   
   \item Desde el punto de vista metodológico, estructurar un programa usando funciones nos permita aplicar una estrategia {\em divide y vencerás} al desarrollo de los programas.
   
   \item A menudo descubriremos que una misma función se puede utilizar en muchos programas. Ya has visto ejemplos: todas las funciones que importamos desde los módulos {\tt math} o {\tt random}, etc. han sido escritas (y son actualizadas) por programadores del equipo de desarrollo de Python, pero todos los demás usuarios nos beneficiamos de ellas. De esa forma, el código agrupado en una función puede reciclarse y compartirse.
   
\end{itemize}
Nos gustaría detenernos en este último punto. Es conveniente recordar, cada vez que usamos las funciones de Python, que nuestro trabajo depende y se beneficia del esfuerzo previo de muchos otros programadores. Tal vez dentro de un tiempo llegues a escribir funciones tan interesantes que puedas compartirlas con la comunidad de programadores y de esa forma contribuir a esta tarea colectiva. 


%' Imagínate que estás escribiendo un programa para calcular el coste (en euros) de producción de un producto. Supongamos que varios componentes de ese producto se pagan en dólares. Eso significa que para calcular el coste tendrás que convertir los precios en dólares a precios en euros. Es una operación muy sencilla, claro. Por ejemplo, hoy la tasa de cambio es 1 US = 0.8813€. Así que en nuestro programa {\em cada vez que tengamos que convertir dólares en euros} basta con usar una línea parecida a esta:
%' <<eval=FALSE, purl=FALSE, background=lngConfig[["python"]]$inColor>>=
%' precioEuros = 0.8813 * precioDolares
%' @
%' Pero el problema es, precisamente como hemos destacado, que tenemos que hacer esto cada vez que aparezca una conversión de moneda en nuestro programa. Además las tasas de cambio entre monedas fluctúan. Para mantener el programa actualizado tendremos que modificar el programa, cambiando cada línea en la que se efectúe un cambio de moneda. 
%' 
%' Desde el comienzo de nuestro trabajo con Python hemos ido aumentando la colección de funciones del lenguaje que conocemos. Las funciones son un ingrediente esencial de cualquier lenguaje de programación moderno.  Pyhton cuenta con una colección extensísima de funciones, especialmente gracias a la enorme cantidad de módulos que podemos importar. Y en esta sección vamos a aprender a escribir nuestras propias funciones.  
%' \begin{itemize}
%'   \item Escribir una función  n
%'   \item En estos primeros tutoriales y en los que veremos a lo largo del resto del curso irás descubriendo nuevas funciones que realizan toda clase de tareas. Desde algunas muy sencillas, hasta otras mucho más complejas. Pero incluo teniendo en cuenta todas esas funciones, pronto descubrirás que a menudo las funciones disponibles  
%' \end{itemize}


\subsection*{Soluciones de algunos ejercicios}


\paragraph{\bf $\bullet$ Ejercicio \ref{tut04:ejercicio01}, pág. \pageref{tut04:ejercicio01}}
\label{tut04:ejercicio01:sol}\quad\\


<<raptor="python", purl=FALSE>>=
# Importamos el módulo random e inicializamos el generador
# de números pseudoaleatorios.
import random as rnd
rnd.seed(2016)
# Elegimos el número de tiradas.
n = 10000
# Generamos los resultados de los dados.
dado1 = [rnd.randrange(1, 7) for _ in range(0, n)]
dado2 = [rnd.randrange(1, 7) for _ in range(0, n)]
# Las correspondientes sumas.
suma = [dado1[_] + dado2[_] for _ in range(0, n)]
# Ahora hacemos la tabla de frecuencias absolutas de las sumas.
import collections as cl
sumaCounter = cl.Counter(suma)
freqAbsolutaSuma = sumaCounter.most_common()
freqAbsolutaSuma.sort()
print(freqAbsolutaSuma)
# Y la tabla de frecuencias relativas:
freqRelativaSuma = [[item[0], item[1]/n] for item in freqAbsolutaSuma]
print("frecuencias relativas de la suma=")
print(freqRelativaSuma)
@
Recuerda comparar estas frecuencias relativas (experimentales) con las probabilidades (teóricas):


\paragraph{\bf $\bullet$ Ejercicio \ref{tut04:ejercicio02}, pág. \pageref{tut04:ejercicio02}}
\label{tut04:ejercicio02:sol}\quad\\

\begin{enumerate}
  \item Suponemos que la tabla de densidad de la variable suma está almacenada en la lista de pares {\tt probabilidadesSuma} que hemos obtenido al principio de la Sección \ref{tut04:subsec:TablaDensidadVariableAleatoriaDiscreta}.
<<raptor="python", purl=FALSE, program="dosDados">>=
print(probabilidadesSuma)
@
Entonces podemos hacer 
<<raptor="python", purl=FALSE, program="dosDados">>=
X = probabilidadesSuma
@
y limitarnos a aplicar el código que hemos visto en este apartado:
<<raptor="python", purl=FALSE, program="dosDados">>=
media = sum([x[0] * x[1] for x in X])
print("Media de X = {0:0.4f}".format(media))
import math as m
varianza = sum([(x[0] - media)**2 * x[1] for x in X])
print("varianza = {0:0.4f}".format(varianza))
sigma = m.sqrt(varianza)
print("desviacion tipica = {0:0.4f}".format(sigma))
@

  \item Debes obtener el valor de la varianza igual a $\frac{35}{6}$, como se indica en el ejemplo.
  
  \item Para obtener la diferencia hacemos:
<<raptor="python", purl=FALSE, program="dosDados">>=
diferencia = [abs(d1 - d2) for d1 in dado1 for d2 in dado2]
@  
La función {\tt abs} sirve para calcular el valor absoluto de la diferencia. Su tabla de frecuencias se obtiene con:
<<raptor="python", purl=FALSE, program="dosDados">>=
diferenciaCounter = cl.Counter(diferencia)
recuentoValoresDiferencia = diferenciaCounter.most_common()
recuentoValoresDiferencia.sort()
print(recuentoValoresDiferencia)
@
Las convertimos en probabilidades con:
<<raptor="python", purl=FALSE, program="dosDados">>=
n = len(diferencia)
print("n=", n)
probabilidadesDiferencia = [[item[0], item[1]/n] for item in recuentoValoresDiferencia]
print("probabilidadesDiferencia=", probabilidadesDiferencia)
@
Y ahora podemos calcular la media, varianza y desviación típica con:
<<raptor="python", purl=FALSE, program="dosDados">>=
Y = probabilidadesDiferencia

media = sum([y[0] * y[1] for y in Y])
print("Media de Y = {0:0.4f}".format(media))
import math as m
varianza = sum([(y[0] - media)**2 * y[1] for y in Y])
print("varianza = {0:0.4f}".format(varianza))
sigma = m.sqrt(varianza)
print("desviacion tipica = {0:0.4f}".format(sigma))
@
En esta ocasión hemos llamado {\tt Y} a la variable diferencia porque ya teníamos una variable {\tt X} en el mismo ejercicio. Pero eso nos obliga a  cambiar el código de cálculo de la media y la varianza, renombrando las variables. No es una buena práctica, porque en esos cambios se pueden introducir errores y porque duplicamos código innecesariamente. Habría sido mejor en todo caso hacer 
<<eval=FALSE, purl=FALSE>>=
X = probabilidadesDiferencia
@
y depués copiar exactamente las mismas líneas de código que usamos cuando {\tt X} era la variable suma. Pero hemos hecho esto precisamente para brindarte la ocasión de reflexionar sobre esto. Incluso la segunda opción, siendo preferible, incluye código duplicado. La mejor solución será evidente una vez que hayamos aprendido a escribir funciones en Python, más adelante en este mismo tutorial.  

\end{enumerate}


\paragraph{\bf $\bullet$ Ejercicio \ref{tut04:ejercicio03}, pág. \pageref{tut04:ejercicio03}}
\label{tut04:ejercicio03:sol}\quad\\

El valor es $F(\frac{8}{3})=0.2$, porque se tiene $2<\frac{8}{3}<4$, así que
\[F(\frac{8}{3}) = P(X \leq \frac{8}{3}) = P(X\leq 2)=F(2) = 0.2\]
La gráfica de la función de distribución (pág. \pageref{tut04:fig:graficoFuncionDistribucion}) puede ayudarte a entender este resultado.



\begin{thebibliography}{99}
\label{bibliografia}
\bibitem{downey2015thinkPython}
Allen Downey.
\newblock {\em Think Python}.
\newblock O'Reilly Media, 2nd edition, 2015.
\newblock Ebook ISBN: 978-1-4919-3935-2
\end{thebibliography}


%#########################################################################################
%#########################################################################################
\vspace{2cm} \hrule
\quad\\
Fin del Tutorial-04. ¡Gracias por la atención!

%\newpage
%\addcontentsline{toc}{section}{Guía de trabajo.}
%\includepdf[pages={1-},scale=0.90]{04-GuiaDeTrabajo.pdf}

\end{document}
